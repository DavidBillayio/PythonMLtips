{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RandomForestRegressor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPX/d4tv960EivLMgDuso4I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavidBillayio/PythonMLtips/blob/master/RandomForestRegressor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTS0N38Mk_Yf"
      },
      "source": [
        "# Random Forest Regressors\n",
        "For this example we seek to predict the sale prices in the test data set. You will notice that the training data has the sale prices listed for a number of homes and the test data is missing the sale prices. \n",
        "\n",
        "Your job is to use the following code to predict the sale prices of the test data homes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XS1XWzgWGoLw"
      },
      "source": [
        "Why use a Random Forest Regressor?\n",
        "\n",
        "A random forest regressor is an ensemble algorithm. This means that the algorithm combines multiple of the same algorithm to make a better predicition than a single instance of the algorithm. Regression is, of-course, the method of predicting a continuous response output.\n",
        "\n",
        "The Random Forest Regressor uses the principle of combining a number of random weak forest classification algorithms by a voting mechanism to create a stronger prediction. \n",
        "\n",
        "A disadvantage to Random Forest Regressors is that it is not infact continuous but still has some disadvantages of a classification tree algoritm in that it does not predict outside of the range of the training data and does not provide a strictly continuous output.\n",
        "\n",
        "bagging - an ensemble meta-algoritm designed to improve stability, reduce variance, and improve accuracy.\n",
        "boosting - an ensemble meta-algorithm for reducing bias and variance in supervised learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WNta5bZigPz"
      },
      "source": [
        "# A simple random forest regressor that is tested and optimized for some parameters.\n",
        "\n",
        "# import the modules\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "print(\"modules imported\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RbY_4iaiyOs"
      },
      "source": [
        "#Read the data\n",
        "\n",
        "full_train_data = pd.read_csv('full_train_data.csv')\n",
        "test_data = pd.read_csv('test_data.csv')\n",
        "\n",
        "# Let's first look at the training data\n",
        "print(full_train_data.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL7mFvtlnJ5k"
      },
      "source": [
        "#Notice that the Lot facing is in North, South, East and West. This can be more effectively interpreted through a One Hot encoder.\n",
        "\n",
        "#first, and most importantly, we make a copy to avoid changing the original data\n",
        "X_train = full_train_data.copy()\n",
        "\n",
        "#import OneHot Encoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "cols = ['lot facing']\n",
        "OH_encoder = OneHotEncoder(sparse = False)\n",
        "OH_train = pd.DataFrame(OH_encoder.fit_transform(X_train[cols]))\n",
        "#notice the new data columns\n",
        "print(OH_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-fL0kGCrMaZ"
      },
      "source": [
        "#But how do we know which is which? By:\n",
        "OH_encoder.categories_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj-ShHj0rs1H"
      },
      "source": [
        "#So we create the new column headings for the One Hot Encoded columns\n",
        "OH_train.columns =['E', 'N', 'S', 'W']\n",
        "\n",
        "\n",
        "#just to double check:\n",
        "print(OH_train)\n",
        "print(X_train)\n",
        "print(X_train['lot facing'].value_counts())\n",
        "OH_train.sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAL9UGsv0CcA"
      },
      "source": [
        "#at a high level it checks out.\n",
        "# We must now add the OH values to the dataframe\n",
        "\n",
        "OH_X_train = pd.concat([X_train,OH_train], axis = 1)\n",
        "print(OH_X_train.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AAlUWEY98pr"
      },
      "source": [
        "#that was a lot of work, let's use something easier for the same result.\n",
        "\n",
        "# We will re-copy our data for the second try\n",
        "\n",
        "X_train2 = full_train_data.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWPJ12kM3bJr"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "transformer = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('lot facing',        # Just a name\n",
        "         OneHotEncoder(), # The transformer class\n",
        "         [3]            # The column(s) to be applied on.\n",
        "         )\n",
        "    ], remainder='passthrough'\n",
        ")\n",
        "OH_X_train2 = pd.DataFrame(transformer.fit_transform(X_train2))\n",
        "OH_X_train2.columns =['E', 'N', 'S', 'W', 'area', 'bedrooms', 'bathrooms', 'saleprice']\n",
        "print(OH_X_train2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWKGOU9V4MKs"
      },
      "source": [
        "#that was much easier. We continue."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqM-P1-rjgVi"
      },
      "source": [
        "#Next, we define the target and features we will be using to predict the sale price\n",
        "\n",
        "#define the target\n",
        "y = OH_X_train2.saleprice\n",
        "\n",
        "#define the features we are interested in using to predict\n",
        "features = ['area', 'bedrooms', 'bathrooms', 'N', 'S', 'E', 'W']\n",
        "\n",
        "#define the input features in a new dataframe\n",
        "X = OH_X_train2[features].copy()\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUsbIurYkqZW"
      },
      "source": [
        "#Separate our training and validation sets from the test data\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X,y, train_size = 0.8, test_size = 0.2, random_state = 0)\n",
        "print(X_train, X_valid, y_train, y_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apOAD5QbmdZm"
      },
      "source": [
        "#We will want to try several models using various parameters to see which model will work best\n",
        "\n",
        "#Define several random forest regressors to compare.\n",
        "model_1 = RandomForestRegressor(n_estimators=50, random_state=0)\n",
        "model_2 = RandomForestRegressor(n_estimators=100, random_state=0)\n",
        "model_3 = RandomForestRegressor(n_estimators=100, criterion='mae', random_state=0)\n",
        "model_4 = RandomForestRegressor(n_estimators=200, min_samples_split=20, random_state=0)\n",
        "model_5 = RandomForestRegressor(n_estimators=10000, max_depth=4, random_state=0)\n",
        "\n",
        "models = [model_1, model_2, model_3, model_4, model_5]\n",
        "print('models loaded')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdr3wif3-r1T"
      },
      "source": [
        "# next we will define a function to score each model\n",
        "\n",
        "def score_model(model, Xt, Xv, Yt, Yv):\n",
        "  \"\"\"takes in the model, the training and validation data and returns the mean absolute error\"\"\"\n",
        "  model.fit(Xt,Yt)\n",
        "  prediction = model.predict(Xv)\n",
        "  return mean_absolute_error(Yv, prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbBdfh12_SZB"
      },
      "source": [
        "for i in range(0,len(models)):\n",
        "  mae = score_model(models[i],X_train, X_valid, y_train, y_valid)\n",
        "  print(\"Model {} MAE: {}\".format(i+1, mae))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxlzyOV2BQ1W"
      },
      "source": [
        "#Is the error good? \n",
        "\n",
        "It doesn't look like it, but we will take the model with the lowest error. What are the issues with this?\n",
        "\n",
        "After all of that, where we doing again? That's right, predicting the test values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "216V1R4ABq-D"
      },
      "source": [
        "#What do we need to do first?\n",
        "\n",
        "#that's right\n",
        "OH_test = pd.DataFrame(transformer.fit_transform(test_data))\n",
        "OH_test.columns =['E', 'N', 'S', 'W', 'area', 'bedrooms', 'bathrooms']\n",
        "print(OH_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGNdrCkCBQEQ"
      },
      "source": [
        "#initiate chosen model\n",
        "chosen_model = model_5\n",
        "\n",
        "chosen_model.fit(X,y)\n",
        "prediction_test = chosen_model.predict(OH_test)\n",
        "output_data = pd.DataFrame({'sale price' : prediction_test})\n",
        "output = pd.concat([test_data,output_data], axis = 1)\n",
        "output.to_csv('submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pQg4PqbL3cN"
      },
      "source": [
        "#Some interesting other information about our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqNWSheBL92c",
        "outputId": "6d058512-d335-442d-ab82-91265cd62bf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "feature_importance = chosen_model.feature_importances_\n",
        "\n",
        "print(\"Feature ranking:\")\n",
        "for i, column in enumerate(OH_test.columns):\n",
        "    print(\"{}. {} \".format(column , feature_importance[i]))\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature ranking:\n",
            "E. 0.6078583837647725 \n",
            "N. 0.11054492785198458 \n",
            "S. 0.12717739801475603 \n",
            "W. 0.01972355786594817 \n",
            "area. 0.06734195486872883 \n",
            "bedrooms. 0.022403869857629183 \n",
            "bathrooms. 0.04494990777618075 \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}